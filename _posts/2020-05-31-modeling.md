---
title: "Weaponizing Science"
tags: [statistics, modeling, science, covid]
excerpt: "Do you believe in science?"
last_modified_at: 2020-05-31
category: [data science, thoughts]
header:
    overlay_image: '/assets/images/modeling/Screen Shot 2021-07-03 at 9.22.33 PM.png'
    overlay_filter: 0.5
---

Statistics is a hard subject. There are no right answers, there are only justified and unjustified claims with giant gray areas. Understanding statistics takes a sophisticated understanding of causality, logic and difficult math. And since there is no simple verification, statisticians have to be risk takers and humble at the same time. Unfortunately, most scientists who rely on statistics don't have a very sophisticated grasp of the tools they're using. Some scientists don't undertsand the statistics they use at all. In fact, not even everyone who has studied statistics understands statistics!

This puts us, the public, in a difficult position as we try to understand the pandemic through mountains of unfiltered data. The task is monumental, and the room for error is enormous. This seems to have gotten to the staff at the New York Times, where they [claimed](https://www.nytimes.com/2020/05/23/reader-center/coronavirus-new-york-times-front-page.html) to publish a list of COVID-19 deaths as a result of "...a fatigue with the data."

People are declaring that they want their leaders to listen to science, calling Trump a [geocentrist](https://www.salon.com/2020/05/03/our-anti-science-leaders-are-the-geocentrists-of-today/), [banning](https://www.bbc.com/news/technology-52388586) medical advice that goes against the WHO guidelines and calling for leaders to ["use science to make important decisions"](https://thehill.com/opinion/healthcare/499952-listen-to-experts-and-tackle-the-toxic-chemical-crisis-contributing-to). 

Many scientists interviewed by the media claim to represent the views of the "scientific community",taking brave stands against ["bullshit"](https://www.theguardian.com/world/2020/apr/28/there-is-no-absolute-truth-an-infectious-disease-expert-on-covid-19-misinformation-and-bullshit).

But what does it mean to listen to the scientists? Does that mean that we should trust their models wihtout understanding them? Even Dr. Anthony Fauci warned us not to look to models like oracles. He seemed to be advocating for more nuance when he [said](https://www.washingtonpost.com/health/2020/04/02/experts-trumps-advisers-doubt-white-houses-240000-coronavirus-deaths-estimate/) “I’ve looked at all the models. I’ve spent a lot of time on the models. They don’t tell you anything. You can’t really rely upon models.”

I think it's helpful to explore what exactly a model is. Going to the [Wikipedia page](https://en.wikipedia.org/wiki/Scientific_modelling) for scientific modelling, I think we get a much more enlightening description of the relationship between science and modelling from John von Neumann:

> ... **the sciences do not try to explain, they hardly even try to interpret, they mainly make models.** By a model is meant a mathematical construct which, with the addition of certain verbal interpretations, describes observed phenomena. The justification of such a mathematical construct is solely and precisely that it is expected to work—that is, correctly to describe phenomena from a reasonably wide area.

**The key idea here is that a model is neither an explanation nor an interpretation.** It is an imperfect tool used to predict.

Here is how I would define a model: A model is an *assumption* about how the world works. We can use our model to *predict* things that have not been observed. And since no model is perfect, hopefully we can report how *confident* we are in our model's prediction.

I think it is helpful to work through an example. Let's suppose that we have a list of trees and we are interested in modelling the relationship between height and volume of the tree. Below is a table of the first 10 examples in the dataset:

|    |   Height (ft.) |   Volume (ft^3) |
|---:|---------:|---------:|
|  0 |       70 |     10.3 |
|  1 |       65 |     10.3 |
|  2 |       63 |     10.2 |
|  3 |       72 |     16.4 |
|  4 |       81 |     18.8 |
|  5 |       83 |     19.7 |
|  6 |       66 |     15.6 |
|  7 |       75 |     18.2 |
|  8 |       80 |     22.6 |
|  9 |       75 |     19.9 |

And here are all 31 examples in a scatter plot:

![Scatter plot](/assets/modeling/treeplot.jpg)

It looks kind of like we could draw  line to fit this data, perhaps something like this:

![assumption](/assets/modeling/assumption.jpg)

Okay, so let's start by making an assumption about the world and defining our model: I propose that the volume of a tree is equal to 2\*height \- 120 (that's the equation of the red line).

Now let's make a prediction. If we come across a new tree that has a height of 85 ft., then we can predict that the volume of the tree is 2\*85-120 = 50 ft. ^3.

How confident are we in this prediction? Well, obviously our model is not literally true, the points on the graph don't lie perfectly on the line. In fact, around the area where height = 85 ft., the points are quite far from the line! This makes me not so confident in my prediction. I'm going to say that I predict the volume to be (50 ± 20) ft.^3. The purple arrows below show this "confidence":

![confidence](/assets/modeling/confidence.jpg)

So we have defined our model and made use of it. We made an **assumption** about trees, and we used it to make a **prediction** about a certain tree's height, and report **confidence** in our prediction.

How do we ordinary people know if we should trust the model though? Well as a statistician, I'll let you know that there are some serious issues with this model. All I did was squint my eyes and draw a line, a statistician has better methods for line fitting. These are complicated and take some time to practice and understand.

Here's a *serious* linear model with a bunch of relevant statistics and metrics. Instead of just drawing a line, the code below picked the *best* line using a method called Ordinary Least Squares (OLS).

```python
import pandas as pd
from matplotlib import pyplot as plt
import statsmodels.api as sm

trees = pd.read_csv('https://forge.scilab.org/index.php/p/rdataset/source/file/master/csv/datasets/trees.csv')

out = sm.OLS(trees['Height'],trees['Volume'])
result = out.fit()
print(result.summary())
```

```

                                 OLS Regression Results                                
=======================================================================================
Dep. Variable:                 Height   R-squared (uncentered):                   0.813
Model:                            OLS   Adj. R-squared (uncentered):              0.807
Method:                 Least Squares   F-statistic:                              130.4
Date:                Sun, 31 May 2020   Prob (F-statistic):                    1.91e-12
Time:                        16:12:06   Log-Likelihood:                         -152.36
No. Observations:                  31   AIC:                                      306.7
Df Residuals:                      30   BIC:                                      308.2
Df Model:                           1                                                  
Covariance Type:            nonrobust                                                  
==============================================================================
                 coef    std err          t      P>|t|      [0.025      0.975]
------------------------------------------------------------------------------
Volume         2.0086      0.176     11.418      0.000       1.649       2.368
==============================================================================
Omnibus:                        7.306   Durbin-Watson:                   0.120
Prob(Omnibus):                  0.026   Jarque-Bera (JB):                6.242
Skew:                          -1.089   Prob(JB):                       0.0441
Kurtosis:                       3.299   Cond. No.                         1.00
==============================================================================
>
Warnings:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
```

But what does this all mean? Is this model better like I suggested? How do we know if we should trust it?

Well it's a good thing I know stats. From this I can see that our model has a BIC of 308.2 and a Durbin-Watson score of 0.120. These are very impressive numbers, which means that this is a very good model.

Okay, I made that all up. In fact, the BIC is meaningless on its own. It's meant to be compared to another BIC.

Why did I lie to you? Well I spent 4 years in college learning about statistics and I wanted people to think that I'm cool. I did get to go to the grad school of my dreams so now I need to find other ways to prove myself.

Wow. That's dark. Okay it's not true, but hopefully you see the point I'm making: you can't believe everything you hear. But where does that leave us? How do we know if we should trust a model or not? Well, as cliche as it sounds, you had the power to tell the whole time!

There are obvious flaws with these models that take no special knowledge to understand. For example, we're only predicting volume from height. This means our models predict the same volume for skinny trees and fat trees! And it takes no education to realize that a tree isn't even cyllindrical. It's thickest at its base and tapers off towards the top. And for reasons I won't get into, it was actually [inppropriate](https://en.wikipedia.org/wiki/Ordinary_least_squares#Assumptions) for me to fit an OLS model to this data. All those numbers I printed out above rest on false assumptions.

And here we get to the main point. You now know what a model is. To reject a model is NOT to reject science. And often rejecting a model doesn't  require scientific credentials, only common sense. Despite any inabillity to interpret or dispute the above printout, you can safely say that this model is a bad model for predicting tree volume.

Yet somehow, today people seem to be unaware of this idea in the midst of the COVID-19 pandemic. Countries that don't impose lockdowns are called anti-science. CNN on two occasions talked over Assistant to the President Peter Navarro as he explained why he [believes in the potential of hydroxychloroquine](https://www.axios.com/peter-navarro-hydroxychloroquine-coronavirus-cnn-a915585b-55dd-4f32-a2ae-b8bb06474973.html) to call him an anti-science ideologue. He responded that he has a PhD which means that he is experienced reading and evluating scientific papers. He also [expressed doubt about the predicted need of ventilators in the US](https://www.cnn.com/videos/politics/2020/03/26/peter-navarro-intv-supply-of-masks-medical-supplies-sot-ath-vpx.cnn).  Similar to this trees example, the best public policy decision is not necessarily the one that agrees with somone's model of how many ventilators we'll need, or what the seniormost virologist in the country is saying. Common sense can play a more important role.

This goes for the controversial [Imperial College study from March](https://www.imperial.ac.uk/media/imperial-college/medicine/sph/ide/gida-fellowships/Imperial-College-COVID19-NPI-modelling-16-03-2020.pdf) that predicted hospital overload in the US and UK. Reading the paper, we can see that a lot of their assumptions came from limited data and studies from China. It is now known that the Chinese government was involved in [covering up coronavirus details and silencing doctors](https://nypost.com/2020/05/06/finally-the-world-is-catching-on-to-chinas-coronavirus-lies/).  

This kind of blind insistence on science isn't new. Greta Thunberg has become a people's champion of science despite merely being a [woke](https://disrn.com/news/greta-thunberg-climate-crisis-not-just-about-environment-but-also-colonial-racist-patriarchal-systems-of-oppression) [political activist](https://www.youtube.com/watch?v=xVlRompc1yE), which is not exactly the mode for open scientific inquiry. Climate activists and COVID alarmists alike are using science as a rallying cry for their public policy agendas, decrying common sense when it runs against their agenda. But as we can see, common sense is essential in the sciences, and ordinary people have the power to use their common sense effectively.